# -*- coding: utf-8 -*-
"""ProyectoML-KC-KevinMarquez.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TlU3-Db6mmJXRfG77bwnZmHwqmEyKpI6

ğŸ“Œ 1ï¸âƒ£ InstalaciÃ³n del entorno y carga del dataset
ğŸ“Œ Antes de comenzar con el anÃ¡lisis, configuramos el entorno, montamos Google Drive y cargamos el dataset. âœ… Instalamos las librerÃ­as necesarias para manipulaciÃ³n de datos y Machine Learning. âœ… Montamos Google Drive para acceder a los archivos almacenados. âœ… Importamos el dataset y realizamos una inspecciÃ³n inicial, revisando columnas, valores nulos y tipos de datos, ademas de primera eliminacion de columnas innecesarias para el modelo.
"""

# ğŸ“Œ InstalaciÃ³n de librerÃ­as esenciales
!pip install pandas numpy matplotlib seaborn scikit-learn

# ğŸ“Œ Montaje de Google Drive
from google.colab import drive
drive.mount('/content/drive')

# ğŸ“Œ ImportaciÃ³n de librerÃ­as necesarias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import Ridge, Lasso
from sklearn.feature_selection import SelectKBest, f_regression

# ğŸ“Œ 1ï¸âƒ£ Carga del dataset desde Google Drive
ruta = "/content/drive/MyDrive/ColabNotebooks/airbnb-listings-extract.csv"
df = pd.read_csv(ruta, delimiter=";")

# ğŸ“Œ 2ï¸âƒ£ InspecciÃ³n inicial
print(f"âœ… Dimensiones del dataset: {df.shape}")
print(f"ğŸ”¹ Columnas disponibles: {df.columns}")
print("\nğŸ“Œ InformaciÃ³n del dataset:")
print(df.info())
print("\nğŸ“Œ EstadÃ­sticas descriptivas:")
print(df.describe())
print("\nğŸ“Œ Valores nulos por columna:")
print(df.isnull().sum())

# ğŸ“Œ 3ï¸âƒ£ Limpieza de datos
# EliminaciÃ³n automÃ¡tica de columnas con mÃ¡s del 50% de valores nulos o identificadores irrelevantes
umbral_nulos = 0.5
columnas_irrelevantes = [col for col in df.columns if df[col].isnull().mean() > umbral_nulos]
columnas_identificadoras = ["ID", "Scrape ID", "Host ID", "Latitude", "Longitude", "Listing Url",
                            "Picture Url", "Geolocation", "Street", "Name", "Description"]
columnas_a_eliminar = list(set(columnas_irrelevantes + columnas_identificadoras))
df = df.drop(columns=[col for col in columnas_a_eliminar if col in df.columns])

# ConversiÃ³n dinÃ¡mica de "Price" a numÃ©rico
if df["Price"].dtype == "object":
    df["Price"] = df["Price"].str.replace("$", "").str.replace(",", "")
df["Price"] = pd.to_numeric(df["Price"], errors="coerce")
df = df.dropna(subset=["Price"])

# ImputaciÃ³n adaptativa de valores `NaN`
columnas_numericas = df.select_dtypes(include=["number"]).columns.tolist()
estrategias_imputacion = {}
for col in columnas_numericas:
    estrategias_imputacion[col] = "most_frequent" if df[col].isnull().mean() > 0.3 else "median"
for col, estrategia in estrategias_imputacion.items():
    imputer = SimpleImputer(strategy=estrategia)
    df[col] = imputer.fit_transform(df[[col]])

# Escalado automÃ¡tico de columnas con alta variabilidad
umbral_variabilidad = 1.0
columnas_a_escalar = df[columnas_numericas].std()[df[columnas_numericas].std() > umbral_variabilidad].index.tolist()
scaler = StandardScaler()
df[columnas_a_escalar] = scaler.fit_transform(df[columnas_a_escalar])

# ğŸ“Œ Resumen despuÃ©s de limpieza
print(f"âœ… Dataset limpio y listo para anÃ¡lisis: {df.shape}")
print(f"ğŸ”¹ Columnas eliminadas automÃ¡ticamente: {columnas_a_eliminar}")
print(f"ğŸ”¹ Columnas escaladas automÃ¡ticamente: {columnas_a_escalar}")

"""Transformamos el dataset para mejorar la calidad de los datos y eliminar informaciÃ³n irrelevante. âœ… Eliminamos columnas con mÃ¡s del 50% de valores nulos o que no aportan a la predicciÃ³n. âœ… Convertimos Price a formato numÃ©rico para garantizar cÃ¡lculos precisos. âœ… Escalamos columnas de alta variabilidad para mejorar el rendimiento del modelo. âœ… Seleccionamos dinÃ¡micamente las caracterÃ­sticas mÃ¡s relevantes con SelectKBest."""

# ğŸ“Œ Filtrar solo columnas numÃ©ricas antes de calcular la correlaciÃ³n
df_numerico = df.select_dtypes(include=["number"])

# ğŸ“Œ Visualizar correlaciÃ³n de variables con "Price"
plt.figure(figsize=(12, 6))
sns.heatmap(df_numerico.corr()[["Price"]].sort_values(by="Price", ascending=False), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("ğŸ”¹ CorrelaciÃ³n de variables con Price")
plt.show()


# ğŸ“Œ 2ï¸âƒ£ SelecciÃ³n dinÃ¡mica de caracterÃ­sticas
k_mejores = min(15, len(df.select_dtypes(include=["number"]).columns) - 1)  # MÃ¡ximo de 15 o nÃºmero total de variables numÃ©ricas

selector = SelectKBest(score_func=f_regression, k=k_mejores)
X = df.drop(columns=["Price"])
y = df["Price"]
X_selected = selector.fit_transform(X.select_dtypes(include=["number"]), y)

# ğŸ“Œ Obtener nombres de las caracterÃ­sticas seleccionadas
columnas_seleccionadas = [col for col, mask in zip(X.select_dtypes(include=["number"]).columns, selector.get_support()) if mask]
print(f"ğŸŒŸ CaracterÃ­sticas seleccionadas automÃ¡ticamente: {columnas_seleccionadas}")

"""Dividimos los datos en conjuntos de entrenamiento y prueba para evaluar el rendimiento del modelo. âœ… Usamos train_test_split con proporciÃ³n del 80%-20% para asegurar un buen equilibrio entre entrenamiento y validaciÃ³n. âœ… Aplicamos validaciÃ³n cruzada en el siguiente paso para mejorar la robustez del modelo."""

# ğŸ“Œ DivisiÃ³n del dataset en entrenamiento y prueba (80%-20%)
X_train, X_test, y_train, y_test = train_test_split(
    df[columnas_seleccionadas], df["Price"], test_size=0.2, random_state=42
)

# ğŸ“Œ Verificar tamaÃ±os de cada conjunto
print(f"âœ… TamaÃ±o del conjunto de entrenamiento: {X_train.shape}")
print(f"âœ… TamaÃ±o del conjunto de prueba: {X_test.shape}")

"""SelecciÃ³n de caracterÃ­sticas con Lasso.

ğŸ“Œ Aplicamos Lasso para filtrar automÃ¡ticamente las variables con menor relevancia en la predicciÃ³n. âœ… Lasso utiliza una penalizaciÃ³n (L1 regularizaciÃ³n) que reduce a 0 los coeficientes de caracterÃ­sticas menos significativas. âœ… Esto mejora la eficiencia del modelo, permitiÃ©ndole centrarse en las variables mÃ¡s influyentes. âœ… Las caracterÃ­sticas con poca aportaciÃ³n al rendimiento se eliminan automÃ¡ticamente, evitando ruido en los datos.

"""

from sklearn.linear_model import LassoCV

# ğŸ“Œ Definir y entrenar el modelo Lasso con validaciÃ³n cruzada
lasso_feature_selector = LassoCV(alphas=np.logspace(-3, 3, 10), cv=5)
lasso_feature_selector.fit(X_train, y_train)

# ğŸ“Œ Identificar caracterÃ­sticas seleccionadas
selected_features_lasso = X_train.columns[lasso_feature_selector.coef_ != 0]
print(f"âœ… CaracterÃ­sticas seleccionadas por Lasso: {selected_features_lasso.tolist()}")

"""ğŸ”¹ SelecciÃ³n de caracterÃ­sticas con RandomForestRegressor
ğŸ“Œ Aplicamos Random Forest para identificar y clasificar las caracterÃ­sticas mÃ¡s influyentes en la predicciÃ³n. âœ… Random Forest crea mÃºltiples Ã¡rboles de decisiÃ³n y analiza el impacto de cada variable en el modelo. âœ… Este mÃ©todo detecta relaciones complejas entre los datos, lo que complementa la selecciÃ³n realizada con Lasso. âœ… Las variables con mayor relevancia serÃ¡n utilizadas en la fase de modelado, maximizando la precisiÃ³n del modelo.

ğŸ”¥ Este paso perfecciona la selecciÃ³n de caracterÃ­sticas y potencia la capacidad predictiva de nuestra soluciÃ³n. ğŸš€
"""

from sklearn.ensemble import RandomForestRegressor

# ğŸ“Œ Definir y entrenar el modelo Random Forest
rf_feature_selector = RandomForestRegressor(n_estimators=100, random_state=42)
rf_feature_selector.fit(X_train, y_train)

# ğŸ“Œ Obtener importancia de cada caracterÃ­stica
feature_importances = pd.DataFrame({'Feature': X_train.columns, 'Importance': rf_feature_selector.feature_importances_})
feature_importances = feature_importances.sort_values(by='Importance', ascending=False)

print("âœ… Ranking de caracterÃ­sticas por RandomForestRegressor:")
print(feature_importances)

"""ğŸ”¹ Entrenamiento de los modelos Ridge y Lasso
ğŸ“Œ Aplicamos regresiÃ³n regularizada (Ridge y Lasso) para mejorar la precisiÃ³n en la predicciÃ³n de precios. âœ… Ridge maneja la multicolinealidad, reduciendo el impacto de variables altamente correlacionadas. âœ… Lasso filtra automÃ¡ticamente las caracterÃ­sticas clave, eliminando aquellas con menor relevancia. âœ… Usamos validaciÃ³n cruzada (cross-validation) para ajustar el valor Ã³ptimo de alpha y mejorar la regularizaciÃ³n del modelo. âœ… Evaluamos los modelos con RMSE y RÂ², comparando su desempeÃ±o en la predicciÃ³n de precios.

ğŸ”¥ Este paso afina la precisiÃ³n del modelo, eliminando ruido y mejorando la estabilidad de las predicciones. ğŸš€
"""

from sklearn.linear_model import RidgeCV, LassoCV
from sklearn.metrics import mean_squared_error, r2_score

# ğŸ“Œ 1ï¸âƒ£ Definir modelos con validaciÃ³n cruzada para ajustar alpha
ridge_model = RidgeCV(alphas=np.logspace(-3, 3, 10), cv=5)
lasso_model = LassoCV(alphas=np.logspace(-3, 3, 10), cv=5)

# ğŸ“Œ 2ï¸âƒ£ Entrenar modelos
ridge_model.fit(X_train[selected_features_lasso], y_train)  # Usamos las caracterÃ­sticas filtradas por Lasso
lasso_model.fit(X_train[selected_features_lasso], y_train)

# ğŸ“Œ 3ï¸âƒ£ Predicciones en el conjunto de prueba
y_pred_ridge = ridge_model.predict(X_test[selected_features_lasso])
y_pred_lasso = lasso_model.predict(X_test[selected_features_lasso])

# ğŸ“Œ 4ï¸âƒ£ EvaluaciÃ³n de desempeÃ±o
rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))
rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))
r2_ridge = r2_score(y_test, y_pred_ridge)
r2_lasso = r2_score(y_test, y_pred_lasso)

# ğŸ“Œ 5ï¸âƒ£ Mostrar resultados
print(f"âœ… Mejor alpha para Ridge: {ridge_model.alpha_}")
print(f"âœ… Mejor alpha para Lasso: {lasso_model.alpha_}")
print(f"ğŸ”¹ RMSE Ridge: {rmse_ridge:.2f}, RÂ² Ridge: {r2_ridge:.2f}")
print(f"ğŸ”¹ RMSE Lasso: {rmse_lasso:.2f}, RÂ² Lasso: {r2_lasso:.2f}")

"""ğŸ”¹ VisualizaciÃ³n de predicciones (y_test vs y_pred)
ğŸ“Œ Antes de continuar con otros modelos, analizamos grÃ¡ficamente el comportamiento de las predicciones. âœ… Usamos scatterplot para comparar los valores reales (y_test) con los valores predichos (y_pred). âœ… Esto nos permite identificar si el modelo subestima o sobreestima los precios. âœ… Si los puntos estÃ¡n alineados con la diagonal, el modelo estÃ¡ haciendo buenas predicciones. âœ… Si hay dispersiÃ³n, significa que el modelo tiene errores y puede necesitar ajustes.

ğŸ”¥ Esta visualizaciÃ³n nos ayudarÃ¡ a evaluar la precisiÃ³n del modelo y decidir si es necesario optimizarlo. ğŸš€
"""

import matplotlib.pyplot as plt
import seaborn as sns
y_pred_ridge_adjusted = (y_pred_ridge * y_test.std()) + y_test.mean()

# ğŸ“Œ VisualizaciÃ³n de las predicciones
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred_ridge_adjusted, alpha=0.8, label="Ridge", color="orange")
sns.scatterplot(x=y_test, y=y_pred_lasso, alpha=0.8, label="Lasso", color="blueviolet")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)  # LÃ­nea ideal
plt.xlabel("Precio real")
plt.ylabel("Precio predicho")
plt.title("ğŸ“Œ ComparaciÃ³n de predicciones Ridge vs Lasso")
plt.legend()
plt.show()

"""ğŸ“Œ Interpretamos la visualizaciÃ³n de las predicciones para evaluar el rendimiento del modelo. âœ… Cada punto representa una predicciÃ³n: Si los puntos estÃ¡n alineados con la lÃ­nea punteada, el modelo estÃ¡ haciendo estimaciones precisas. âœ… Si hay demasiada dispersiÃ³n, significa que el modelo tiene errores altos, lo que podrÃ­a indicar problemas en la selecciÃ³n de caracterÃ­sticas o la necesidad de ajustar hiperparÃ¡metros. âœ… Los valores alejados de la lÃ­nea punteada pueden representar outliers, casos en los que el modelo no captura correctamente el precio real. âœ… Esta visualizaciÃ³n nos ayuda a identificar si el modelo requiere ajustes adicionales, como regularizaciÃ³n o cambios en la selecciÃ³n de variables.

ğŸ”¹ IncorporaciÃ³n de RandomForestRegressor y XGBoostRegressor
ğŸ“Œ Probamos modelos avanzados para evaluar si mejoran la precisiÃ³n en la predicciÃ³n de precios. âœ… RandomForestRegressor utiliza mÃºltiples Ã¡rboles de decisiÃ³n, lo que le permite capturar relaciones no lineales y patrones complejos en los datos. âœ… XGBoostRegressor es un modelo basado en boosting, optimizando predicciones mediante correcciones iterativas de errores en cada Ã¡rbol. âœ… Ambos modelos suelen tener un mejor desempeÃ±o que la regresiÃ³n lineal tradicional (Ridge y Lasso) en conjuntos de datos con mÃºltiples factores. âœ… Compararemos su rendimiento con RMSE y RÂ², verificando si reducen el error y aumentan la precisiÃ³n de la predicciÃ³n.

ğŸ”¥ Este paso nos ayudarÃ¡ a determinar quÃ© modelo es el mÃ¡s adecuado para la predicciÃ³n de precios de alojamientos. ğŸš€
"""

from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor

# ğŸ“Œ Definir y entrenar Random Forest
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train[selected_features_lasso], y_train)
y_pred_rf = rf_model.predict(X_test[selected_features_lasso])

# ğŸ“Œ Definir y entrenar XGBoost
xgb_model = XGBRegressor(n_estimators=100, random_state=42)
xgb_model.fit(X_train[selected_features_lasso], y_train)
y_pred_xgb = xgb_model.predict(X_test[selected_features_lasso])

# ğŸ“Œ EvaluaciÃ³n de desempeÃ±o
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))
rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))
r2_rf = r2_score(y_test, y_pred_rf)
r2_xgb = r2_score(y_test, y_pred_xgb)

print(f"ğŸ”¹ RMSE Random Forest: {rmse_rf:.2f}, RÂ² Random Forest: {r2_rf:.2f}")
print(f"ğŸ”¹ RMSE XGBoost: {rmse_xgb:.2f}, RÂ² XGBoost: {r2_xgb:.2f}")

"""ğŸ”¹ Entrenamiento de RandomForestRegressor y XGBoostRegressor
ğŸ“Œ Compararemos estos modelos avanzados con Ridge y Lasso para analizar si mejoran la precisiÃ³n en la predicciÃ³n de precios. âœ… Entrenamos RandomForestRegressor y XGBoostRegressor utilizando los mismos datos, garantizando comparabilidad en los resultados. âœ… Calculamos RMSE y RÂ² para verificar si estos modelos tienen menor error y explican mejor la variabilidad en los precios. âœ… Si RMSE disminuye y RÂ² aumenta respecto a Ridge y Lasso, significa que estos modelos son mÃ¡s precisos y manejan mejor relaciones complejas en los datos.

ğŸ”¥ Este anÃ¡lisis nos permitirÃ¡ determinar si RandomForestRegressor y XGBoostRegressor son la mejor opciÃ³n para la predicciÃ³n de precios. ğŸš€

Usaremos scatterplot para comparar los valores reales (y_test) contra los valores predichos (y_pred). âœ… Esto nos permitirÃ¡ evaluar si Random Forest y XGBoost mejoran las predicciones en comparaciÃ³n con Ridge y Lasso. âœ… Si los puntos estÃ¡n cerca de la lÃ­nea diagonal, el modelo estÃ¡ haciendo buenas predicciones.
"""

# ğŸ“Œ VisualizaciÃ³n de las predicciones de Random Forest y XGBoost
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred_rf, alpha=0.8, label="Random Forest", color="green")
sns.scatterplot(x=y_test, y=y_pred_xgb, alpha=0.8, label="XGBoost", color="purple")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)  # LÃ­nea ideal
plt.xlabel("Precio real")
plt.ylabel("Precio predicho")
plt.title("ğŸ“Œ ComparaciÃ³n de predicciones Random Forest vs XGBoost")
plt.legend()
plt.show()

"""ğŸš€ OptimizaciÃ³n de XGBoost y RandomForestRegressor con GridSearchCV
ğŸ“Œ Ajustamos los hiperparÃ¡metros para mejorar la precisiÃ³n en la predicciÃ³n de precios. âœ… Entrenamos los modelos sin optimizaciÃ³n para establecer una referencia y evaluar su desempeÃ±o inicial. âœ… Aplicamos GridSearchCV para encontrar los mejores valores de learning_rate, max_depth y n_estimators en XGBoost. âœ… Para RandomForestRegressor, probamos n_estimators, max_depth, min_samples_split y min_samples_leaf, asegurando que cada parÃ¡metro optimizado contribuya a un mejor ajuste del modelo. âœ… Comparamos ambos modelos antes y despuÃ©s de la optimizaciÃ³n para analizar el impacto y determinar cuÃ¡l ofrece una mejor precisiÃ³n.

ğŸ“Œ Â¿CÃ³mo interpretar los resultados? ğŸ”¹ Si RMSE disminuye y RÂ² aumenta despuÃ©s de la optimizaciÃ³n, el modelo ha mejorado significativamente su capacidad predictiva. ğŸ”¹ Comparar RandomForest y XGBoost nos permitirÃ¡ identificar cuÃ¡l maneja mejor la variabilidad y los patrones ocultos en los datos. ğŸ”¹ Los valores optimizados nos ayudarÃ¡n a ajustar los modelos para un mejor rendimiento en escenarios reales.

ğŸ”¥ Este ajuste nos permitirÃ¡ tomar decisiones fundamentadas sobre el modelo mÃ¡s preciso para la predicciÃ³n de precios de alojamientos. ğŸš€
"""

from sklearn.model_selection import GridSearchCV

# ğŸ“Œ Definir hiperparÃ¡metros para XGBoost
param_grid_xgb = {
    "learning_rate": [0.01, 0.05, 0.1, 0.3],
    "max_depth": [3, 5, 7, 10],
    "n_estimators": [50, 100, 200]
}

# ğŸ“Œ Optimizar XGBoost
grid_search_xgb = GridSearchCV(XGBRegressor(random_state=42), param_grid_xgb, cv=5, scoring="neg_root_mean_squared_error", n_jobs=-1)
grid_search_xgb.fit(X_train[selected_features_lasso], y_train)

best_xgb = XGBRegressor(**grid_search_xgb.best_params_, random_state=42)
best_xgb.fit(X_train[selected_features_lasso], y_train)
y_pred_best_xgb = best_xgb.predict(X_test[selected_features_lasso])

# ğŸ“Œ Definir hiperparÃ¡metros para Random Forest
param_grid_rf = {
    "n_estimators": [50, 100, 200],
    "max_depth": [None, 10, 20],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4]
}

# ğŸ“Œ Optimizar Random Forest
grid_search_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=5, scoring="neg_root_mean_squared_error", n_jobs=-1)
grid_search_rf.fit(X_train[selected_features_lasso], y_train)

best_rf = RandomForestRegressor(**grid_search_rf.best_params_, random_state=42)
best_rf.fit(X_train[selected_features_lasso], y_train)
y_pred_best_rf = best_rf.predict(X_test[selected_features_lasso])

# ğŸ“Œ EvaluaciÃ³n de desempeÃ±o optimizado
rmse_best_xgb = np.sqrt(mean_squared_error(y_test, y_pred_best_xgb))
r2_best_xgb = r2_score(y_test, y_pred_best_xgb)
rmse_best_rf = np.sqrt(mean_squared_error(y_test, y_pred_best_rf))
r2_best_rf = r2_score(y_test, y_pred_best_rf)

print(f"âœ… Mejores hiperparÃ¡metros para XGBoost: {grid_search_xgb.best_params_}")
print(f"âœ… Mejores hiperparÃ¡metros para Random Forest: {grid_search_rf.best_params_}")
print(f"ğŸ”¹ RMSE XGBoost (optimizado): {rmse_best_xgb:.2f}, RÂ² XGBoost: {r2_best_xgb:.2f}")
print(f"ğŸ”¹ RMSE Random Forest (optimizado): {rmse_best_rf:.2f}, RÂ² Random Forest: {r2_best_rf:.2f}")

"""ğŸ”¹ ComparaciÃ³n de modelos (RMSE y RÂ²)
ğŸ“Œ Generamos una tabla comparativa para visualizar el desempeÃ±o de todos los modelos probados. âœ… Cada modelo se evalÃºa con RMSE y RÂ², midiendo su precisiÃ³n en la predicciÃ³n de precios de alojamientos. âœ… Los valores se obtienen directamente de los resultados generados, evitando ingresar datos manualmente. âœ… Las versiones optimizadas de RandomForestRegressor y XGBoostRegressor muestran la mejora tras la optimizaciÃ³n con GridSearchCV. âœ… Este anÃ¡lisis nos ayudarÃ¡ a determinar quÃ© modelo es el mÃ¡s preciso y adecuado para la tarea de predicciÃ³n.

ğŸ“Œ Â¿CÃ³mo interpretar los resultados? ğŸ”¹ Un menor RMSE indica menor error en la predicciÃ³n. ğŸ”¹ Un mayor RÂ² indica que el modelo explica mejor la variabilidad en los datos. ğŸ”¹ Comparar modelos optimizados y sin optimizar nos permitirÃ¡ ver si la optimizaciÃ³n realmente ha mejorado el rendimiento.
"""

from sklearn.metrics import mean_squared_error, r2_score

# ğŸ“Œ Calcular los valores de RMSE y RÂ² para cada modelo
rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))
rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))
rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))
rmse_best_rf = np.sqrt(mean_squared_error(y_test, y_pred_best_rf))
rmse_best_xgb = np.sqrt(mean_squared_error(y_test, y_pred_best_xgb))

r2_ridge = r2_score(y_test, y_pred_ridge)
r2_lasso = r2_score(y_test, y_pred_lasso)
r2_rf = r2_score(y_test, y_pred_rf)
r2_xgb = r2_score(y_test, y_pred_xgb)
r2_best_rf = r2_score(y_test, y_pred_best_rf)
r2_best_xgb = r2_score(y_test, y_pred_best_xgb)

# ğŸ“Œ Crear un DataFrame con los resultados reales obtenidos
model_comparison = pd.DataFrame({
    "Modelo": ["Ridge Regression", "Lasso Regression", "RandomForestRegressor", "XGBoostRegressor"],
    "RMSE Inicial": [rmse_ridge, rmse_lasso, rmse_rf, rmse_xgb],
    "RÂ² Inicial": [r2_ridge, r2_lasso, r2_rf, r2_xgb],
    "RMSE Optimizado": [None, None, rmse_best_rf, rmse_best_xgb],
    "RÂ² Optimizado": [None, None, r2_best_rf, r2_best_xgb]
})

# ğŸ“Œ Mostrar la tabla comparativa
print("ğŸ“Š ComparaciÃ³n de modelos en tÃ©rminos de RMSE y RÂ²:")
print(model_comparison)

# ğŸ“Œ Definir los nombres de los modelos
model_names = ["Ridge", "Lasso", "RandomForest", "XGBoost", "RandomForest (Optimizado)", "XGBoost (Optimizado)"]

# ğŸ“Œ Obtener los valores de RMSE y RÂ² directamente de los resultados calculados
rmse_values = [rmse_ridge, rmse_lasso, rmse_rf, rmse_xgb, rmse_best_rf, rmse_best_xgb]
r2_values = [r2_ridge, r2_lasso, r2_rf, r2_xgb, r2_best_rf, r2_best_xgb]

# ğŸ“Œ Configurar el grÃ¡fico de barras
x = np.arange(len(model_names))  # PosiciÃ³n de las barras
width = 0.3  # Ancho de las barras

fig, ax = plt.subplots(figsize=(10, 6))

# ğŸ“Œ Graficar RMSE y RÂ²
ax.bar(x - width/2, rmse_values, width, label="RMSE", color="red", alpha=0.7)
ax.bar(x + width/2, r2_values, width, label="RÂ²", color="blue", alpha=0.7)

# ğŸ“Œ PersonalizaciÃ³n del grÃ¡fico
ax.set_xticks(x)
ax.set_xticklabels(model_names, rotation=45, ha="right")
ax.set_ylabel("Valores")
ax.set_title("ğŸ“Š ComparaciÃ³n de Modelos - RMSE y RÂ²")
ax.legend()

plt.show()

"""ğŸ“Œ ExplicaciÃ³n del grÃ¡fico: âœ… Compara RMSE y RÂ² de cada modelo, mostrando cÃ³mo han mejorado tras la optimizaciÃ³n. âœ… Se visualiza claramente que XGBoost optimizado tiene el menor RMSE y el mayor RÂ², destacando su precisiÃ³n. âœ… Los modelos sin optimizaciÃ³n (Ridge, Lasso, RandomForest y XGBoost inicial) permiten evaluar cuÃ¡nto han mejorado con GridSearchCV.

ğŸ”¹ ConclusiÃ³n General
ğŸ“Œ DespuÃ©s de probar mÃºltiples modelos de regresiÃ³n, hemos identificado cuÃ¡l es el mÃ¡s eficiente para predecir precios de alojamientos.

âœ… Ridge y Lasso fueron buenas opciones iniciales, permitiendo manejar la multicolinealidad y seleccionar caracterÃ­sticas clave. âœ… RandomForestRegressor y XGBoostRegressor demostraron un mejor rendimiento, capturando relaciones no lineales y mejorando la precisiÃ³n de las predicciones. âœ… Tras la optimizaciÃ³n con GridSearchCV, XGBoostRegressor mostrÃ³ el mejor desempeÃ±o, con el menor RMSE y el mayor RÂ², consolidÃ¡ndose como la mejor alternativa para la predicciÃ³n de precios. âœ… La selecciÃ³n de caracterÃ­sticas con Lasso y RandomForestRegressor ayudÃ³ a reducir el ruido, mejorando la estabilidad del modelo. âœ… La comparaciÃ³n grÃ¡fica y cuantitativa confirmÃ³ que los modelos optimizados son superiores a los modelos iniciales, lo que demuestra la importancia de ajustar hiperparÃ¡metros.
"""